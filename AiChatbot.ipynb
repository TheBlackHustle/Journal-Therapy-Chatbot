
!{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Specify the folder containing your journal entries\n",
    "folder_path = '/Users/devinjackson/Documents/PycharmProjects/Journal Project/Entries/'\n",
    "\n",
    "# Get a list of all text files in the folder\n",
    "file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.txt')]\n",
    "\n",
    "# Initialize an empty list to hold all documents\n",
    "documents = []\n",
    "\n",
    "# Load each file into the documents list\n",
    "for file_path in file_paths:\n",
    "    loader = TextLoader(file_path)\n",
    "    documents += loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0.3, openai_api_key=\"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\")\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_query\"],\n",
    "    template=\"Create a set of keywords based on the user query: '{user_query}' to perform a search on the journal dataset in Chroma DB.\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "userinput = input(\"Hey im a journl help bot, how can i help you today? \")\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "keywords = chain.run(userinput)\n",
    "\n",
    "# Convert keywords to string, assuming keywords is a list of words\n",
    "keywords_str = \" \".join(keywords)\n",
    "\n",
    "# Query Chroma
       "docs = db.similarity_search(keywords_str, k=1)\n",
        "\n",
        "# Process the documents\n",
        "full_result_string = \"\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "template = \"\"\"You are a chatbot. Be kind, detailed and nice. Present the given queried search result in a nice way as answer to the user input. dont ask questions back! just take the given context\n",
        "\n",
        "{chat_history}\n",
        "Human: {user_msg}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"user_msg\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(model_name=\"gpt-4\", temperature=0.8, openai_api_key=\"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\"),\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "answer = llm_chain.predict(user_msg=f\"{full_result_string} ---\\n\\n {userinput}\")\n",
        "print(\"Bot:\", answer)\n",
        "\n",
        "while True:\n",
        "    follow_up = input(\"Anything else you want to ask about this topic? (type 'quit' to stop) \")\n",
        "    print()\n"
        "]\n",
}
